{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "from scipy.fft import fft\n",
    "from scipy.spatial.distance import euclidean\n",
    "from python_speech_features import mfcc\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Divide the signal into frames\n",
    "def frame_signal(signal, frame_length, frame_step):\n",
    "    num_samples = len(signal)\n",
    "    num_frames = 1 + int(np.ceil((num_samples - frame_length) / frame_step))\n",
    "    frames = np.zeros((num_frames, frame_length))\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        start = i * frame_step\n",
    "        end = min(start + frame_length, num_samples)\n",
    "        frames[i, :end - start] = signal[start:end]\n",
    "\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Compute spectrum using FFT for each frame\n",
    "def compute_spectrum(frames):\n",
    "    return np.abs(fft(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute average frames for each speech class in the training set\n",
    "def compute_average_frames(train_data, train_labels, classes):\n",
    "    class_avg_frames = {}\n",
    "\n",
    "    for class_name in classes:\n",
    "        class_indices = np.where(train_labels == class_name)[0]\n",
    "        class_frames = train_data[class_indices]\n",
    "        avg_frame = np.mean(class_frames, axis=0)\n",
    "        class_avg_frames[class_name] = avg_frame\n",
    "\n",
    "    return class_avg_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 4: Compute features for the test wave file and compute distances for each speech class\n",
    "def compute_distances(test_features, class_avg_frames):\n",
    "    distances = {}\n",
    "\n",
    "    for class_name, avg_frame in class_avg_frames.items():\n",
    "\n",
    "        flat_test_features = test_features.flatten()\n",
    "        flat_avg_frame = avg_frame.flatten()\n",
    "\n",
    "        distance = euclidean(flat_test_features, flat_avg_frame)\n",
    "        distances[class_name] = distance\n",
    "        print(f\"Distance to class '{class_name}': {distance}\")\n",
    "\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the testing set: 63.00%\n",
      "The predicted class for 'D:\\\\jupyter.ipynb\\\\mini_speech\\\\mini_speech_commands\\\\up\\\\0c5027de_nohash_0.wav' is: up\n",
      "Distance to class 'down': 488.2716048918962\n",
      "Distance to class 'go': 487.78051999504936\n",
      "Distance to class 'left': 488.76282393436065\n",
      "Distance to class 'no': 488.45731478534674\n",
      "Distance to class 'right': 488.72223496138474\n",
      "Distance to class 'stop': 485.50903171604784\n",
      "Distance to class 'up': 486.69094788438383\n",
      "Distance to class 'yes': 490.2543374655764\n",
      "Euclidean distance to class 'down': 488.2716048918962\n",
      "Euclidean distance to class 'go': 487.78051999504936\n",
      "Euclidean distance to class 'left': 488.76282393436065\n",
      "Euclidean distance to class 'no': 488.45731478534674\n",
      "Euclidean distance to class 'right': 488.72223496138474\n",
      "Euclidean distance to class 'stop': 485.50903171604784\n",
      "Euclidean distance to class 'up': 486.69094788438383\n",
      "Euclidean distance to class 'yes': 490.2543374655764\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Pick the class with the smallest distance\n",
    "def predict_class(distances):\n",
    "    return min(distances, key=distances.get)\n",
    "\n",
    "# Load the dataset\n",
    "data_dir = r'D:\\\\jupyter.ipynb\\\\mini_speech\\\\mini_speech_commands'\n",
    "classes = os.listdir(data_dir)\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "max_length = 100  # Define the maximum length for features\n",
    "\n",
    "# Extract features for the training set\n",
    "for class_name in classes:\n",
    "    class_dir = os.path.join(data_dir, class_name)\n",
    "    filenames = os.listdir(class_dir)\n",
    "\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.wav'):\n",
    "            filepath = os.path.join(class_dir, filename)\n",
    "            _, signal = wav.read(filepath)\n",
    "            features = mfcc(signal)\n",
    "            \n",
    "            if len(features) < max_length:\n",
    "                features = np.pad(features, ((0, max_length - len(features)), (0, 0)), mode='constant')\n",
    "            else:\n",
    "                features = features[:max_length, :]\n",
    "            train_data.append(features)\n",
    "            train_labels.append(class_name)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "# Reshape the features to have a consistent shape\n",
    "num_samples, num_frames, num_features = train_data.shape[0], train_data.shape[1], train_data.shape[2]\n",
    "train_data_reshaped = train_data.reshape(num_samples, num_frames * num_features)\n",
    "\n",
    "# Preprocess data\n",
    "scaler = StandardScaler()\n",
    "train_data_scaled = scaler.fit_transform(train_data_reshaped)\n",
    "\n",
    "\n",
    "test_size = 0.2\n",
    "random_state = 42\n",
    "train_data_split, test_data_split, train_labels_split, test_labels_split = train_test_split(\n",
    "    train_data_scaled, train_labels, test_size=test_size, random_state=random_state\n",
    ")\n",
    "class_avg_frames = compute_average_frames(train_data_split, train_labels_split, classes)\n",
    "\n",
    "# Train a simple KNN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(train_data_split, train_labels_split)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_predictions = knn.predict(test_data_split)\n",
    "accuracy = accuracy_score(test_labels_split, test_predictions)\n",
    "print(f\"Accuracy on the testing set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Example for testing a sample file\n",
    "test_file = r'D:\\\\jupyter.ipynb\\\\mini_speech\\\\mini_speech_commands\\\\up\\\\0c5027de_nohash_0.wav'\n",
    "test_rate, test_signal = wav.read(test_file)\n",
    "test_features = mfcc(test_signal)\n",
    "# Pad or truncate the test features to the defined maximum length\n",
    "if len(test_features) < max_length:\n",
    "    test_features = np.pad(test_features, ((0, max_length - len(test_features)), (0, 0)), mode='constant')\n",
    "else:\n",
    "    test_features = test_features[:max_length, :]\n",
    "\n",
    "# Reshape and preprocess the test data\n",
    "test_features_reshaped = test_features.reshape(1, -1)\n",
    "test_features_scaled = scaler.transform(test_features_reshaped)\n",
    "\n",
    "# Predict the class and print the Euclidean distance for each class\n",
    "predicted_class = knn.predict(test_features_scaled)\n",
    "print(f\"The predicted class for '{test_file}' is: {predicted_class[0]}\")\n",
    "\n",
    "# Compute distances to each class\n",
    "distances_to_classes = compute_distances(test_features_reshaped, class_avg_frames)\n",
    "\n",
    "# Print distances for each class\n",
    "for class_name, distance in distances_to_classes.items():\n",
    "    print(f\"Euclidean distance to class '{class_name}': {distance}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
